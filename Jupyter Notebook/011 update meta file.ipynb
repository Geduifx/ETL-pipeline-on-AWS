{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "dd4dad0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3 # Python integration with AWS.\n",
    "import pandas as pd # Read csv.\n",
    "from io import StringIO, BytesIO # StringIO to read csv on AWS. BytesIO to save as Parquet file to S3.\n",
    "from datetime import datetime, timedelta # Date functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389e7409",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2c4a9724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapter Layer Functions\n",
    "\n",
    "def read_csv_to_df(bucket, key, decoding = 'utf-8', sep = ','):\n",
    "    csv_obj = bucket.Object(key=key).get().get('Body').read().decode(decoding)\n",
    "    # Read csvs with StringIO (needed for AWS) and Pandas\n",
    "    data = StringIO(csv_obj)\n",
    "    df = pd.read_csv(data, delimiter=sep)\n",
    "    return df\n",
    "\n",
    "def write_df_to_s3(bucket, df, key):\n",
    "    out_buffer = BytesIO()\n",
    "    df.to_parquet(out_buffer, index=False)\n",
    "    bucket.put_object(Body=out_buffer.getvalue(), Key=key)\n",
    "    return True\n",
    "\n",
    "# Update meta csv file\n",
    "def write_df_to_s3_csv(bucket, df, key):\n",
    "    out_buffer = StringIO()\n",
    "    df.to_csv(out_buffer, index=False)\n",
    "    bucket.put_object(Body=out_buffer.getvalue(), Key=key)\n",
    "    return True\n",
    "\n",
    "def list_files_in_prefix(bucket, prefix):\n",
    "    files = [obj.key for obj in bucket.objects.filter(Prefix=prefix)]\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "85aa8360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application Layer Functions, ETL\n",
    "\n",
    "def extract(bucket, date_list):\n",
    "    files = [key for date in date_list for key in list_files_in_prefix(bucket, date)]\n",
    "    df = pd.concat([read_csv_to_df(bucket, obj) for obj in files], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def transform_report1(df, columns, arg_date):\n",
    "    # DF with filtered columns.\n",
    "    df = df.loc[:, columns]\n",
    "    # Filter out empty lines.\n",
    "    df.dropna(inplace=True)\n",
    "    # Get opening price per ISIN and day\n",
    "    # Create new column with opening price.\n",
    "    df['opening_price'] = df.sort_values(by=['Time']).groupby(['ISIN', 'Date'])['StartPrice'].transform('first')\n",
    "    # Get closing price per ISIN and day\n",
    "    # Create new column with closing price.\n",
    "    df['closing_price'] = df.sort_values(by=['Time']).groupby(['ISIN', 'Date'])['StartPrice'].transform('last')\n",
    "    # Aggregation\n",
    "    df = df.groupby(['ISIN', 'Date'], as_index=False).agg(opening_price_eur=('opening_price', 'min'), closing_price_eur=('closing_price', 'min'), minimum_price_eur=('MinPrice', 'min'), maximum_price_eur=('MaxPrice', 'max'), daily_traded_volume=('TradedVolume', 'sum'))\n",
    "    # Percent Change Prev Closing\n",
    "    df['prev_closing_price'] = df.sort_values(by=['Date']).groupby(['ISIN'])['closing_price_eur'].shift(1)\n",
    "    df['change_prev_closing_%'] = (df['closing_price_eur'] - df['prev_closing_price']) / df['prev_closing_price'] * 100\n",
    "    # Remove column and update df\n",
    "    df.drop(columns=['prev_closing_price'], inplace=True)\n",
    "    # Round everything.\n",
    "    df = df.round(decimals=2)\n",
    "    # Filter by date, don't show previous date that was used for calculation.\n",
    "    df = df[df.Date >= arg_date]\n",
    "    return df\n",
    "\n",
    "def load(bucket, df, trg_key, trg_format, meta_key, extract_date_list):\n",
    "    # Write to S3.\n",
    "    key = trg_key + datetime.today().strftime(\"%Y%m%d_%H%M%S\") + trg_format\n",
    "    write_df_to_s3(bucket, df, key)\n",
    "    update_meta_file(bucket, meta_key, extract_date_list)\n",
    "    return True\n",
    "\n",
    "# Combine all three ETL functions.\n",
    "def etl_report1(scr_bucket, trg_bucket, date_list, columns, arg_date, trg_key, trg_format, meta_key):\n",
    "    df = extract(scr_bucket, date_list)\n",
    "    df = transform_report1(df, columns, arg_date)\n",
    "    extract_date_list = [date for date in date_list if date >= arg_date]\n",
    "    load(trg_bucket, df, trg_key, trg_format, meta_key, extract_date_list)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a14ba477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application layer - not core\n",
    "\n",
    "# Restructure get_objects\n",
    "def return_date_list(bucket, arg_date, scr_format, meta_key):\n",
    "    # Convert to date type and use previous day\n",
    "    min_date = datetime.strptime(arg_date, scr_format).date() - timedelta(days=1)\n",
    "    today = datetime.today().date()\n",
    "    \n",
    "    # Using meta_file.csv        \n",
    "    try:\n",
    "        df_meta = read_csv_to_df(bucket, meta_key)\n",
    "        dates = [(min_date + timedelta(days=x)) for x in range(0, (today-min_date).days + 1)]\n",
    "        # Dates list from meta file\n",
    "        src_dates = set(pd.to_datetime(df_meta['source_date']).dt.date)\n",
    "        # Min date\n",
    "        dates_missing = set(dates[1:]) - src_dates\n",
    "        if dates_missing:\n",
    "            min_date = min(set(dates[1:]) - src_dates) - timedelta(days=1)\n",
    "            return_dates = [date.strftime(scr_format) for date in dates if date >= min_date]\n",
    "            return_min_date = (min_date + timedelta(days=1)).strftime(scr_format)\n",
    "        else:\n",
    "            return_dates = []\n",
    "            return_min_date = datetime(2200, 1, 1).date()\n",
    "    except bucket.session.client('s3').execptions.NoSuchKey:\n",
    "   \n",
    "\n",
    "        # Return date list in string format if meta file is empty\n",
    "        return_dates = [(min_date + timedelta(days=x)).strftime(scr_format) for x in range(0, (today-min_date).days + 1)]\n",
    "        return_min_date = arg_date\n",
    "    return return_min_date, return_dates\n",
    "\n",
    "def update_meta_file(bucket, meta_key, extract_date_list):\n",
    "    df_new = pd.DataFrame(columns=['source_date', 'datetime_of_processing'])\n",
    "    df_new['source_date'] = extract_date_list\n",
    "    df_new['datetime_of_processing'] = datetime.today().strftime('%Y-%m-%d')\n",
    "    df_old = read_csv_to_df(bucket, meta_key)\n",
    "    df_all = pd.concat([df_old, df_new])\n",
    "    write_df_to_s3_csv(bucket, df_all, meta_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "49baa35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function entrypoint\n",
    "\n",
    "def main():\n",
    "    # Parameters/Configurations\n",
    "    # Later read config\n",
    "    # Argument Date for start of report\n",
    "    arg_date = '2022-11-26'\n",
    "    # Moving all arguments and parameters to the beggining of the code\n",
    "    scr_format = '%Y-%m-%d'\n",
    "    scr_bucket = 'xetra-1234'\n",
    "    trg_bucket = 'manoetl123'\n",
    "    columns = ['ISIN', 'Date', 'Time', 'StartPrice', 'MaxPrice', 'MinPrice', 'EndPrice', 'TradedVolume']\n",
    "    trg_key = 'xetra_daily_report_'\n",
    "    trg_format = '.parquet'\n",
    "    meta_key = 'meta_file.csv'\n",
    "    \n",
    "    # Init\n",
    "    # Variables for data on AWS S3.\n",
    "    s3 = boto3.resource('s3')\n",
    "    bucket_scr = s3.Bucket(scr_bucket)\n",
    "    bucket_trg = s3.Bucket(trg_bucket)\n",
    "    \n",
    "    # run application\n",
    "    extract_date, date_list = return_date_list(bucket_trg, arg_date, scr_format, meta_key)\n",
    "    etl_report1(bucket_scr, bucket_trg, date_list, columns, extract_date, trg_key, trg_format, meta_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "acf52b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141413dd",
   "metadata": {},
   "source": [
    "## Read the uploaded file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "88291718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta_file.csv\n",
      "xetra_daily_report_20221122_222801.parquet\n",
      "xetra_daily_report_20221122_233442.parquet\n",
      "xetra_daily_report_20221123_183552.parquet\n",
      "xetra_daily_report_20221124_210807.parquet\n",
      "xetra_daily_report_20221127_195456.parquet\n",
      "xetra_daily_report_20221127_200047.parquet\n",
      "xetra_daily_report_20221127_201807.parquet\n"
     ]
    }
   ],
   "source": [
    "trg_bucket = 'manoetl123'\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_trg = s3.Bucket(trg_bucket)\n",
    "\n",
    "# Read the uploaded file\n",
    "for obj in bucket_trg.objects.all():\n",
    "    print(obj.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ba481f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prq_obj = bucket_trg.Object(key='xetra_daily_report_20221127_201807.parquet').get().get('Body').read()\n",
    "data = BytesIO(prq_obj)\n",
    "df_report = pd.read_parquet(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a3494b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISIN</th>\n",
       "      <th>Date</th>\n",
       "      <th>opening_price_eur</th>\n",
       "      <th>closing_price_eur</th>\n",
       "      <th>minimum_price_eur</th>\n",
       "      <th>maximum_price_eur</th>\n",
       "      <th>daily_traded_volume</th>\n",
       "      <th>change_prev_closing_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AT000000STR1</td>\n",
       "      <td>2022-11-26</td>\n",
       "      <td>36.10</td>\n",
       "      <td>37.70</td>\n",
       "      <td>36.10</td>\n",
       "      <td>37.70</td>\n",
       "      <td>2864</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AT000000STR1</td>\n",
       "      <td>2022-11-27</td>\n",
       "      <td>36.10</td>\n",
       "      <td>37.70</td>\n",
       "      <td>36.10</td>\n",
       "      <td>37.70</td>\n",
       "      <td>2864</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AT00000FACC2</td>\n",
       "      <td>2022-11-26</td>\n",
       "      <td>7.90</td>\n",
       "      <td>8.36</td>\n",
       "      <td>7.86</td>\n",
       "      <td>8.36</td>\n",
       "      <td>2490</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AT00000FACC2</td>\n",
       "      <td>2022-11-27</td>\n",
       "      <td>7.90</td>\n",
       "      <td>8.36</td>\n",
       "      <td>7.86</td>\n",
       "      <td>8.36</td>\n",
       "      <td>2490</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AT0000606306</td>\n",
       "      <td>2022-11-26</td>\n",
       "      <td>16.88</td>\n",
       "      <td>17.15</td>\n",
       "      <td>16.50</td>\n",
       "      <td>17.86</td>\n",
       "      <td>115948</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6289</th>\n",
       "      <td>XS2314660700</td>\n",
       "      <td>2022-11-27</td>\n",
       "      <td>22.37</td>\n",
       "      <td>21.86</td>\n",
       "      <td>21.86</td>\n",
       "      <td>22.37</td>\n",
       "      <td>598</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6290</th>\n",
       "      <td>XS2376095068</td>\n",
       "      <td>2022-11-26</td>\n",
       "      <td>34.28</td>\n",
       "      <td>34.90</td>\n",
       "      <td>34.28</td>\n",
       "      <td>35.08</td>\n",
       "      <td>1360</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6291</th>\n",
       "      <td>XS2376095068</td>\n",
       "      <td>2022-11-27</td>\n",
       "      <td>34.28</td>\n",
       "      <td>34.90</td>\n",
       "      <td>34.28</td>\n",
       "      <td>35.08</td>\n",
       "      <td>1360</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6292</th>\n",
       "      <td>XS2434891219</td>\n",
       "      <td>2022-11-26</td>\n",
       "      <td>3.44</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.44</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6293</th>\n",
       "      <td>XS2434891219</td>\n",
       "      <td>2022-11-27</td>\n",
       "      <td>3.44</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.44</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6294 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ISIN        Date  opening_price_eur  closing_price_eur  \\\n",
       "0     AT000000STR1  2022-11-26              36.10              37.70   \n",
       "1     AT000000STR1  2022-11-27              36.10              37.70   \n",
       "2     AT00000FACC2  2022-11-26               7.90               8.36   \n",
       "3     AT00000FACC2  2022-11-27               7.90               8.36   \n",
       "4     AT0000606306  2022-11-26              16.88              17.15   \n",
       "...            ...         ...                ...                ...   \n",
       "6289  XS2314660700  2022-11-27              22.37              21.86   \n",
       "6290  XS2376095068  2022-11-26              34.28              34.90   \n",
       "6291  XS2376095068  2022-11-27              34.28              34.90   \n",
       "6292  XS2434891219  2022-11-26               3.44               3.50   \n",
       "6293  XS2434891219  2022-11-27               3.44               3.50   \n",
       "\n",
       "      minimum_price_eur  maximum_price_eur  daily_traded_volume  \\\n",
       "0                 36.10              37.70                 2864   \n",
       "1                 36.10              37.70                 2864   \n",
       "2                  7.86               8.36                 2490   \n",
       "3                  7.86               8.36                 2490   \n",
       "4                 16.50              17.86               115948   \n",
       "...                 ...                ...                  ...   \n",
       "6289              21.86              22.37                  598   \n",
       "6290              34.28              35.08                 1360   \n",
       "6291              34.28              35.08                 1360   \n",
       "6292               3.44               3.50                    0   \n",
       "6293               3.44               3.50                    0   \n",
       "\n",
       "      change_prev_closing_%  \n",
       "0                       0.0  \n",
       "1                       0.0  \n",
       "2                       0.0  \n",
       "3                       0.0  \n",
       "4                       0.0  \n",
       "...                     ...  \n",
       "6289                    0.0  \n",
       "6290                    0.0  \n",
       "6291                    0.0  \n",
       "6292                    0.0  \n",
       "6293                    0.0  \n",
       "\n",
       "[6294 rows x 8 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae35651",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
